{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Repository Process Metrics Extraction and Matching with Product Metrics Dataset\n",
    "\n",
    "Data Sources: \n",
    "- [Bavota et al. (2016)](https://figshare.com/articles/An_Experimental_Investigation_on_the_Innate_Relationship_between_Quality_and_Refactoring/1207916)\n",
    "- [Apache Ant Mirror Repository](https://github.com/apache/ant)\n",
    "\n",
    "Paper References: \n",
    "- Tanaka D., Choi E., Yoshida N., Fujiwara K., Port D., Iida H. (20xx). An Investigation of the Relationship Between Extract Method and Process Metrics. The Institute of Electronics, Information and Communication Engineers.\n",
    "- Kumar, L., & Sureka, A. (2017). Application of LSSVM and SMOTE on Seven Open Source Projects for Predicting Refactoring at Class Level. Asia-Pacific Software Engineering Conference (APSEC 2017), 90–99. https://doi.org/10.1109/APSEC.2017.15\n",
    "- Bavota, G., De Lucia, A., Di Penta, M., Oliveto, R., & Palomba, F. (2015). An experimental investigation on the innate relationship between quality and refactoring. Journal of Systems and Software, 107, 1–14. https://doi.org/10.1016/j.jss.2015.05.024\n",
    "- Lee, T., Nam, J., Han, D., Kim, S., & In, H. P. (2011). Micro Interaction Metrics for Defect Prediction. Proceedings of the 19th ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering, 5589(c), 311–321. https://doi.org/10.1145/2025113.2025156\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10,5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directories\n",
    "\n",
    "data_dir = \"data/raw/badsmells/data/\"\n",
    "projects = [\"apache-ant\", \"xerces2-j\"]\n",
    "\n",
    "ddata_dir = \"data/transformed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset and dropping duplicates\n",
    "prod_df = pd.DataFrame()\n",
    "bs_df = pd.DataFrame()\n",
    "\n",
    "for p in projects:\n",
    "    p_dir = data_dir + p + \"/\" + p + \"/\"\n",
    "    for f in os.listdir(p_dir):\n",
    "        if f.endswith(\"metrics.csv\"):\n",
    "            df = pd.read_csv(p_dir + f, sep=\";\", index_col=False)\n",
    "            df[\"proj\"] = p\n",
    "            prod_df = prod_df.append(df)\n",
    "        elif f.endswith(\"antipatterns.csv\"):\n",
    "            df = pd.read_csv(p_dir + f, sep=\";\", index_col=False)\n",
    "            df[\"proj\"] = p\n",
    "            bs_df = bs_df.append(df)\n",
    "            \n",
    "prod_df.drop_duplicates(inplace=True)\n",
    "bs_df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLOB\n",
      "CDSBP\n",
      "ComplexClass\n",
      "LazyClass\n",
      "LongMethod\n",
      "LongParameterList\n",
      "MessageChain\n",
      "RPB\n",
      "SpaghettiCode\n",
      "SpeculativeGenerality\n",
      "FeatureEnvy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bs_cols = ['BLOB', 'CDSBP', 'ComplexClass',\n",
    "       'LazyClass', 'LongMethod', 'LongParameterList', 'MessageChain', 'RPB',\n",
    "       'SpaghettiCode', 'SpeculativeGenerality', 'FeatureEnvy',]\n",
    "for col in bs_cols:\n",
    "    bs_df[col] = bs_df[col].apply(lambda x: 0 if x is False else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_df = pd.merge(prod_df, bs_df, on=[\"Refactoring\", \"Version\", \"Class\", \"proj\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available versions: ['1.1' '1.2' '1.3' '1.4' '1.4.1' '1.5' '1.5.1' '1.5.4' '1.6.0' '1.6.1'\n",
      " '1.6.2' '1.6.3' '1.6.4' '1.7.0' '1.7.1' '1.8.0' '1.8.1' '1.8.2' '1.0.0'\n",
      " '1.0.4' '1.2.0' '1.2.1' '1.2.2' '1.2.3' '1.3.0' '1.3.1' '1.4.0' '1.4.2'\n",
      " '1.4.3' '1.4.4' '2.0.0' '2.0.0alpha' '2.0.0beta' '2.0.0beta2' '2.0.0beta3'\n",
      " '2.0.0beta4' '2.0.1' '2.0.2' '2.1.0' '2.2.0' '2.2.1' '2.3.0' '2.4.0'\n",
      " '2.5.0' '2.6.0' '2.6.1' '2.6.2' '2.7.0' '2.7.1' '2.8.0' '2.8.1' '2.9.0']\n",
      "nVersions: 52\n"
     ]
    }
   ],
   "source": [
    "# Standardization of version names\n",
    "dversions = []\n",
    "for ver in prod_df[\"Version\"]:\n",
    "    dver = \"\"\n",
    "    for i in ver.split(\".\"):\n",
    "        if len(i) == 2 and i[0] == \"0\":\n",
    "            dver = dver + i[1] + \".\"\n",
    "            continue\n",
    "        dver = dver + i + \".\"\n",
    "    dversions.append(dver.rstrip(\".\"))\n",
    "prod_df[\"Version\"] = dversions\n",
    "prod_df[\"Version\"] = prod_df[\"Version\"].replace(to_replace=\"1.8.0final\", value=\"1.8.0\")\n",
    "prod_df[\"Version\"].value_counts()\n",
    "\n",
    "print(\"Available versions: {}\".format(prod_df[\"Version\"].unique()))\n",
    "print(\"nVersions: {}\".format(len(prod_df[\"Version\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "xer_sel_versions = ['2.0.1', '2.0.2', '2.1.0', '2.2.0', '2.2.1', '2.3.0', '2.4.0', '2.5.0', '2.6.0', '2.6.1', '2.6.2', '2.7.0', '2.7.1']\n",
    "ant_sel_versions = ['1.5', '1.5.1', '1.5.4', '1.6.0', '1.6.1', '1.6.2', '1.6.3', '1.6.4', '1.7.0', '1.7.1', '1.8.0', '1.8.1', '1.8.2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Metrics Extraction\n",
    "Will only consider versions 1.5 onwards for stability. Revision split points\n",
    "- 1:5\n",
    "- 2:4\n",
    "- 3:3\n",
    "- 4:2\n",
    "- 5:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== SPLIT 0 =====\n",
      "==========================\n",
      "==> Processing AG and NDC..\n",
      "==> Processing ADD & DEL..\n",
      "==> Processing CHURN..\n",
      "===== SPLIT 1 =====\n",
      "==========================\n",
      "==> Processing AG and NDC..\n",
      "==> Processing ADD & DEL..\n",
      "==> Processing CHURN..\n",
      "===== SPLIT 2 =====\n",
      "==========================\n",
      "==> Processing AG and NDC..\n",
      "==> Processing ADD & DEL..\n",
      "==> Processing CHURN..\n",
      "===== SPLIT 3 =====\n",
      "==========================\n",
      "==> Processing AG and NDC..\n",
      "==> Processing ADD & DEL..\n",
      "==> Processing CHURN..\n",
      "===== SPLIT 4 =====\n",
      "==========================\n",
      "==> Processing AG and NDC..\n",
      "==> Processing ADD & DEL..\n",
      "==> Processing CHURN..\n",
      "===== SPLIT 0 =====\n",
      "==========================\n",
      "==> Processing AG and NDC..\n",
      "==> Processing ADD & DEL..\n",
      "==> Processing CHURN..\n",
      "===== SPLIT 1 =====\n",
      "==========================\n",
      "==> Processing AG and NDC..\n",
      "==> Processing ADD & DEL..\n",
      "==> Processing CHURN..\n",
      "===== SPLIT 2 =====\n",
      "==========================\n",
      "==> Processing AG and NDC..\n",
      "==> Processing ADD & DEL..\n",
      "==> Processing CHURN..\n",
      "===== SPLIT 3 =====\n",
      "==========================\n",
      "==> Processing AG and NDC..\n",
      "==> Processing ADD & DEL..\n",
      "==> Processing CHURN..\n",
      "===== SPLIT 4 =====\n",
      "==========================\n",
      "==> Processing AG and NDC..\n",
      "==> Processing ADD & DEL..\n",
      "==> Processing CHURN..\n",
      "CPU times: user 1min 4s, sys: 3min 12s, total: 4min 17s\n",
      "Wall time: 24min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proc_proj_df = pd.DataFrame()\n",
    "\n",
    "for proj in projects:\n",
    "    os.chdir(\"ghrepos/{}/\".format(proj))\n",
    "    \n",
    "    proj_df = prod_df[prod_df[\"proj\"] == proj]\n",
    "    \n",
    "    if proj == \"xerces2-j\":\n",
    "        sel_versions = xer_sel_versions\n",
    "        ver_prepend = \"Xerces-J_\"\n",
    "        starts_w = (\"dom\", \"dom3\", \"javax\", \"jaxp\", \"sax\", \"socket\", \"simplety\", \"ui\", \"util\", \"xni\", \"xs\", \"org\")\n",
    "        \n",
    "    else:\n",
    "        sel_versions = ant_sel_versions\n",
    "        ver_prepend = \"rel/\"\n",
    "        starts_w = (\"main\", \"org\")\n",
    "        \n",
    "    split_points = range(0, len(sel_versions), 2)\n",
    "    proc_period = []\n",
    "    ref_period = []\n",
    "    for i in range(1, 6):\n",
    "        proc_period.append(sel_versions[:split_points[i]+1])\n",
    "        ref_period.append(sel_versions[split_points[i]+1:])\n",
    "\n",
    "    info_cols = ['Refactoring', 'Version', 'Class']\n",
    "    for split in range(len(proc_period)):\n",
    "        print(\"===== SPLIT {} =====\".format(split))\n",
    "        # Get the start and end of process metrics period versions\n",
    "        start_proc, end_proc = proc_period[split][0], proc_period[split][-1]\n",
    "        if proj == \"xerces2-j\":\n",
    "            start_proc, end_proc = start_proc.replace(\".\", \"_\"), end_proc.replace(\".\", \"_\")\n",
    "        start_comm = subprocess.check_output('git rev-list -n 1 {}{}'.format(ver_prepend, start_proc), shell=True)[:8].decode(\"utf-8\")\n",
    "        end_comm = subprocess.check_output('git rev-list -n 1 {}{}'.format(ver_prepend, end_proc), shell=True)[:8].decode(\"utf-8\")\n",
    "\n",
    "        # Get the rows with version inside the ref period\n",
    "        met_df = proj_df[proj_df[\"Version\"].isin(proc_period[split])][info_cols]\n",
    "        ref_df = proj_df[proj_df[\"Version\"].isin(ref_period[split])]\n",
    "\n",
    "        # For NC (Number of changes)\n",
    "#         print(\"==> Processing NC..\")\n",
    "#         output = subprocess.check_output(\"git diff --name-only {}{} {}{}\".format(ver_prepend, start_proc, ver_prepend, end_proc), shell=True)\n",
    "        \n",
    "#         diff_classes_raw = [i for i in str(output).split(\"\\\\n\") if i.endswith(\".java\") and i.lstrip(\"src/\").startswith(starts_w)]\n",
    "#         diff_classes = [i.lstrip(\"src/\").rstrip(\".java\").replace(\"/\",\".\") for i in diff_classes_raw]\n",
    "        \n",
    "#         diff_classes = set(diff_classes) & set(met_df[\"Class\"].values)\n",
    "#         met_df[\"NC\"] = met_df[\"Class\"].apply(lambda x: 1 if x in diff_classes else 0)\n",
    "\n",
    "        # For NDC (Number of Distinct Committers)  \n",
    "        # For AG (Age of revision)\n",
    "        print(\"==========================\")\n",
    "        print(\"==> Processing AG and NDC..\")\n",
    "        \n",
    "        met_df[\"AG\"] = 0\n",
    "        met_df[\"NDC\"] = 0\n",
    "        for i in met_df[\"Class\"].unique():\n",
    "            class_str_name = \"src/\" + i.replace(\".\",\"/\") + \".java\"\n",
    "            rth_commit = subprocess.check_output(\"git log {} --format=%ct {} | head -n1\".format(end_comm, class_str_name), shell=True)\n",
    "            first_commit = subprocess.check_output(\"git log --format=%ct {} | tail -1\".format(class_str_name), shell=True)\n",
    "            \n",
    "            if first_commit != b'' and rth_commit != b'':\n",
    "                dt = int(rth_commit) - int(first_commit)\n",
    "                met_df.loc[met_df.Class==i, \"AG\"] = dt\n",
    "            authors = subprocess.check_output(\"git shortlog -s {}{}...{}{} -- {}\".format(ver_prepend, start_proc, ver_prepend, end_proc, class_str_name), shell=True)\n",
    "            if authors != \"b''\":\n",
    "                n_authors = len([i.strip().split(\"\\t\") for i in authors.decode(\"utf-8\").strip(\"\\n\").split(\"\\n\") if len(i)>0])\n",
    "                met_df.loc[met_df.Class==i, \"NDC\"] = n_authors\n",
    "\n",
    "        # For ADD and DEL\n",
    "        print(\"==> Processing ADD & DEL..\")\n",
    "        output = subprocess.check_output(\"git diff --numstat {} {} | grep -E '*.java'\".format(start_comm, end_comm), shell=True)\n",
    "        add_del_df = pd.DataFrame([entry.split(\"\\\\t\") for entry in str(output).lstrip(\"b'\").split(\"\\\\n\")], columns=[\"ADD\", \"DEL\", \"Class\"])\n",
    "        add_del_df.dropna(axis=0, subset=[\"Class\"], inplace=True)\n",
    "\n",
    "        add_del_df = add_del_df[(add_del_df[\"Class\"].str.startswith(tuple([\"src/\" + i for i in starts_w])))]\n",
    "        add_del_df[\"Class\"] = add_del_df[\"Class\"].apply(lambda x: x.lstrip(\"src/\").rstrip(\".java\").replace(\"/\", \".\"))\n",
    "        met_df = pd.merge(met_df, add_del_df, how=\"left\", on=\"Class\")\n",
    "\n",
    "        # For CHURN\n",
    "        print(\"==> Processing CHURN..\")\n",
    "        met_df[\"CHURN\"] = met_df[\"ADD\"] + met_df[\"DEL\"]\n",
    "\n",
    "        met_df[\"nsplit\"] = split + 1\n",
    "\n",
    "        new_df = pd.merge(met_df, ref_df, on=['Class', 'Refactoring'])\n",
    "        proc_proj_df = proc_proj_df.append(new_df)\n",
    "\n",
    "    os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xerces2-j     95512\n",
       "apache-ant    87939\n",
       "Name: proj, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_proj_df[\"proj\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Refactoring', 'Version_x', 'Class', 'AG', 'NDC', 'ADD', 'DEL', 'CHURN',\n",
       "       'nsplit', 'Version_y', 'LOC', 'WMC', 'DIT', 'NOC', 'RFC', 'CBO', 'LCOM',\n",
       "       'NOM', 'NOA', 'NOO', 'CCBC', 'C3', 'proj', 'BLOB', 'CDSBP',\n",
       "       'ComplexClass', 'LazyClass', 'LongMethod', 'LongParameterList',\n",
       "       'MessageChain', 'RPB', 'SpaghettiCode', 'SpeculativeGenerality',\n",
       "       'FeatureEnvy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_proj_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_proj_df.to_csv(ddata_dir+\"proc_prod.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_proj_df[proc_proj_df[\"proj\"]==\"apache-ant\"].to_csv(ddata_dir+\"apache.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    95256\n",
       "1      256\n",
       "Name: SpaghettiCode, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc_proj_df[proc_proj_df[\"proj\"]==\"xerces2-j\"][\"SpaghettiCode\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
